---

# Fake Review Detection Project

This project aims to detect fake reviews using **Machine Learning techniques**. The workflow includes **data preprocessing, feature engineering, model training, evaluation, web scraping, and building a website interface** (partially implemented).

---

## üìå Project Workflow

1. **Checkpoint 1: Data Preprocessing**
2. **Checkpoint 2: Fake Review Detection (Model Training & Evaluation)**
3. **Checkpoint 3: Web Scraping Reviews**
4. **Checkpoint 4: Website for Fake Review Detection** *(In Progress)*

---

## üßπ Data Preprocessing (Checkpoint 1)

### Steps Involved

1. **Loading Data** ‚Äì Load dataset into the environment.
2. **Data Cleaning** ‚Äì Handle missing values, remove duplicates, drop irrelevant data.
3. **Text Normalization** ‚Äì Convert text to lowercase, remove special characters, punctuation, and numbers.
4. **Tokenization** ‚Äì Split text into words, remove stopwords.
5. **Stemming & Lemmatization** ‚Äì Reduce words to their base form.
6. **Feature Representation** ‚Äì

   * Bag-of-Words (BoW)
   * TF-IDF (Term Frequency-Inverse Document Frequency)
   * Word Embeddings (e.g., GloVe)

‚úÖ The preprocessed dataset was saved into a **CSV file** for model training.

**Key Learnings**:

* Word embeddings perform better for context-based tasks.
* Preprocessing improves performance by removing noise.

---

## ü§ñ Fake Review Detection (Checkpoint 2)

### Models Used

1. **Random Forest Classifier** ‚Äì Ensemble method for improved accuracy.
2. **Support Vector Machine (SVM)** ‚Äì Finds optimal hyperplane for classification.
3. **Logistic Regression** ‚Äì Linear classifier for binary classification.

### Steps

* **Data Splitting** ‚Äì Train (80%) / Test (20%).
* **Pipeline Creation** ‚Äì Scaling + Model.
* **Training & Evaluation** ‚Äì Accuracy, Precision, Recall, F1-Score.
* **Hyperparameter Tuning** ‚Äì GridSearchCV for best parameters.
* **Model Saving** ‚Äì Models saved using `joblib` for later use.

**Example Results (Random Forest):**

```
Accuracy: ~75%  
Precision: 0.73 - 0.77  
Recall: 0.70 - 0.80  
F1-Score: 0.73 - 0.76  
```

---

## üï∏Ô∏è Web Scraping Reviews (Checkpoint 3)

### Basic Components of Web Scraping

1. **Website Analysis**

   * Inspect HTML structure using Developer Tools.
   * Identify tags for reviews, ratings, reviewer names, and dates.

2. **Libraries & Tools**

   * `requests` ‚Üí Fetch HTML content.
   * `BeautifulSoup` or `lxml` ‚Üí Parse HTML.

3. **Scraping Reviews**

   * Extract review text from product pages.
   * Handle multi-line reviews & embedded HTML tags.

4. **Save Data**

   * Store extracted reviews into **`Reviews.csv`** for further use.

---

## üåê Website for Fake Review Detection (Checkpoint 4 ‚Äì In Progress)

The goal is to create a website that allows users to input a product URL, scrape its reviews, and classify them as **Real** or **Fake**.

### Components

1. **Frontend Development**

   * Input field for product URL.
   * Button to start scraping & classification.
   * Display results: review text + classification (Real/Fake).
   * Tech Options: React, Angular, Vue.js, or basic HTML/CSS/JS.

2. **Backend Development**

   * Use web scraping script from Checkpoint 3.
   * Load trained ML models from Checkpoint 2.
   * Create an **API endpoint**:

     * Accepts product URL.
     * Scrapes reviews.
     * Classifies them.
     * Returns JSON response.

3. **Data Flow**

   * User enters product URL ‚Üí Frontend.
   * Backend scrapes reviews + classifies them.
   * Backend sends JSON ‚Üí Frontend displays results.

‚ö†Ô∏è **Current Status**:
Checkpoint 4 is **not yet fully implemented**. Scraping and model classification work independently, but integration into a web application is pending.

---

## üöÄ Future Work

* Complete **Checkpoint 4** (Frontend + Backend integration).
* Deploy the web app using **Flask/FastAPI + React/HTML frontend**.
* Add visualization dashboards for classification statistics.
* Extend dataset with more real-world reviews for higher accuracy.

---

## üíæ Model Saving & Loading

```python
import joblib
joblib.dump(pipeline, 'fake_review_model.pkl')
```

Models can be reloaded anytime for predictions without retraining.

---

‚úÖ **Status Summary**

* ‚úîÔ∏è Data preprocessing done
* ‚úîÔ∏è Model training & evaluation completed
* ‚úîÔ∏è Web scraping implemented
* ‚è≥ Website integration (Checkpoint 4) still in progress

---
